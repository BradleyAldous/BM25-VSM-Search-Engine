{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeS4WON90flx"
   },
   "source": [
    "# Search Engine Implementation\n",
    "see https://ir-datasets.com/beir.html#beir/scifact  \n",
    "and https://ir-datasets.com/python.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 20275,
     "status": "ok",
     "timestamp": 1647985248465,
     "user": {
      "displayName": "Alexander C",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06292930002536064627"
     },
     "user_tz": 0
    },
    "id": "5Qh8yMNt6QeI"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#!pip install --upgrade ir_datasets\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import ir_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647985251950,
     "user": {
      "displayName": "Alexander C",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06292930002536064627"
     },
     "user_tz": 0
    },
    "id": "i1g2Gf2LjToC",
    "outputId": "226b3659-26ea-4066-fc92-9b0e43a493d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5183 documents with: {'doc_id': <class 'str'>, 'text': <class 'str'>, 'title': <class 'str'>}\n",
      "809 queries with: {'query_id': <class 'str'>, 'text': <class 'str'>}\n",
      "919 qrels with: {'query_id': <class 'str'>, 'doc_id': <class 'str'>, 'relevance': <class 'int'>, 'iteration': <class 'str'>}\n"
     ]
    }
   ],
   "source": [
    "dataset = ir_datasets.load(\"beir/scifact/train\")\n",
    "\n",
    "print(dataset.docs_count(), 'documents with:', dataset.docs_cls().__annotations__)\n",
    "print(dataset.queries_count(), 'queries with:', dataset.queries_cls().__annotations__)\n",
    "print(dataset.qrels_count(), 'qrels with:',dataset.qrels_cls().__annotations__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1647985398363,
     "user": {
      "displayName": "Alexander C",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06292930002536064627"
     },
     "user_tz": 0
    },
    "id": "WIDi1JwIjh7R"
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#this actually downloads the data, muted to avoid clutter\n",
    "#for doc in dataset.docs_iter()[:1]: \n",
    "#    None\n",
    "#for q in dataset.queries_iter():\n",
    " #   None\n",
    "#for qrel in dataset.qrels_iter():\n",
    " #   None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1647985400960,
     "user": {
      "displayName": "Alexander C",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06292930002536064627"
     },
     "user_tz": 0
    },
    "id": "pkhFTCerkCNh"
   },
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for doc in dataset.docs_iter():\n",
    "    corpus.append([doc[0],doc[1],doc[2]])\n",
    "\n",
    "documents = [doc[1] for doc in corpus] \n",
    "# only taking the text for simplicity, but we'll need the doc_id for the evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing all numbers, punctuation and excess whitespace. This can potentially be a part of the data preprocessing section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # remove numbers\n",
    "    text_nonum = re.sub(r'\\d+', '', text)\n",
    "    # remove punctuation and convert characters to lower case\n",
    "    text_nopunct = \"\".join([char.lower() for char in text_nonum if char not in string.punctuation]) \n",
    "    # substitute multiple whitespace with single whitespace and remove leading and trailing whitespaces\n",
    "    text_no_doublespace = re.sub('\\s+', ' ', text_nopunct).strip()\n",
    "    return text_no_doublespace\n",
    "\n",
    "documents_cleaned = []\n",
    "\n",
    "for d in documents:\n",
    "    x = clean_text(d)\n",
    "    documents_cleaned.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "documents_tokenized = []\n",
    "\n",
    "for d in documents_cleaned:\n",
    "    x = word_tokenize(d)\n",
    "    documents_tokenized.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "documents_lemmatized = []\n",
    "\n",
    "for d in documents_tokenized:\n",
    "    y = []\n",
    "    for word in d:\n",
    "        x = wordnet_lemmatizer.lemmatize(word)\n",
    "        y.append(x)\n",
    "    documents_lemmatized.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snow_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "documents_stemmed = []\n",
    "        \n",
    "for d in documents_lemmatized:\n",
    "    stems = []\n",
    "    for word in d:\n",
    "        x = snow_stemmer.stem(word)\n",
    "        stems.append(x)\n",
    "    documents_stemmed.append(stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting back to full strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_indexed = []\n",
    "\n",
    "for doc in documents_stemmed:\n",
    "    documents_indexed.append(' '.join(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing (with included stop word removal):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 2180,
     "status": "ok",
     "timestamp": 1647985409255,
     "user": {
      "displayName": "Alexander C",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06292930002536064627"
     },
     "user_tz": 0
    },
    "id": "G3E7sQ5_kg9x",
    "outputId": "1ec1e09d-14f1-4eff-bced-5103219a908b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>14</th>\n",
       "      <th>a142</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaatpas</th>\n",
       "      <th>aaafamili</th>\n",
       "      <th>aab</th>\n",
       "      <th>aabenhus</th>\n",
       "      <th>aacr</th>\n",
       "      <th>aacrthi</th>\n",
       "      <th>...</th>\n",
       "      <th>zygos</th>\n",
       "      <th>zygot</th>\n",
       "      <th>zymographi</th>\n",
       "      <th>zymosan</th>\n",
       "      <th>zymosaninduc</th>\n",
       "      <th>zyxin</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzw</th>\n",
       "      <th>zzz</th>\n",
       "      <th>zzzw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5178</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5180</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5181</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5182</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5183 rows × 30868 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      14  a142  aa  aaa  aaaatpas  aaafamili  aab  aabenhus  aacr  aacrthi  \\\n",
       "0      0     0   0    0         0          0    0         0     0        0   \n",
       "1      0     0   0    0         0          0    0         0     0        0   \n",
       "2      0     0   0    0         0          0    0         0     0        0   \n",
       "3      0     0   0    0         0          0    0         0     0        0   \n",
       "4      0     0   0    0         0          0    0         0     0        0   \n",
       "...   ..   ...  ..  ...       ...        ...  ...       ...   ...      ...   \n",
       "5178   0     0   0    0         0          0    0         0     0        0   \n",
       "5179   0     0   0    0         0          0    0         0     0        0   \n",
       "5180   0     0   0    0         0          0    0         0     0        0   \n",
       "5181   0     0   0    0         0          0    0         0     0        0   \n",
       "5182   0     0   0    0         0          0    0         0     0        0   \n",
       "\n",
       "      ...  zygos  zygot  zymographi  zymosan  zymosaninduc  zyxin  zz  zzw  \\\n",
       "0     ...      0      0           0        0             0      0   0    0   \n",
       "1     ...      0      0           0        0             0      0   0    0   \n",
       "2     ...      0      0           0        0             0      0   0    0   \n",
       "3     ...      0      0           0        0             0      0   0    0   \n",
       "4     ...      0      0           0        0             0      0   0    0   \n",
       "...   ...    ...    ...         ...      ...           ...    ...  ..  ...   \n",
       "5178  ...      0      0           0        0             0      0   0    0   \n",
       "5179  ...      0      0           0        0             0      0   0    0   \n",
       "5180  ...      0      0           0        0             0      0   0    0   \n",
       "5181  ...      0      0           0        0             0      0   0    0   \n",
       "5182  ...      0      0           0        0             0      0   0    0   \n",
       "\n",
       "      zzz  zzzw  \n",
       "0       0     0  \n",
       "1       0     0  \n",
       "2       0     0  \n",
       "3       0     0  \n",
       "4       0     0  \n",
       "...   ...   ...  \n",
       "5178    0     0  \n",
       "5179    0     0  \n",
       "5180    0     0  \n",
       "5181    0     0  \n",
       "5182    0     0  \n",
       "\n",
       "[5183 rows x 30868 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', strip_accents='ascii')\n",
    "documents_vectorized = vectorizer.fit_transform(documents_indexed)\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "dataframe = pd.DataFrame(documents_vectorized.toarray(), columns=vocabulary)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 5306,
     "status": "ok",
     "timestamp": 1647985416823,
     "user": {
      "displayName": "Alexander C",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06292930002536064627"
     },
     "user_tz": 0
    },
    "id": "OtpbYAsEk7up",
    "outputId": "104e6332-4c18-4387-aad0-ce546b52e39f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>14</th>\n",
       "      <th>a142</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaatpas</th>\n",
       "      <th>aaafamili</th>\n",
       "      <th>aab</th>\n",
       "      <th>aabenhus</th>\n",
       "      <th>aacr</th>\n",
       "      <th>aacrthi</th>\n",
       "      <th>...</th>\n",
       "      <th>zygos</th>\n",
       "      <th>zygot</th>\n",
       "      <th>zymographi</th>\n",
       "      <th>zymosan</th>\n",
       "      <th>zymosaninduc</th>\n",
       "      <th>zyxin</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzw</th>\n",
       "      <th>zzz</th>\n",
       "      <th>zzzw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5178</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5180</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5181</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5182</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5183 rows × 30868 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       14  a142   aa  aaa  aaaatpas  aaafamili  aab  aabenhus  aacr  aacrthi  \\\n",
       "0     0.0   0.0  0.0  0.0       0.0        0.0  0.0       0.0   0.0      0.0   \n",
       "1     0.0   0.0  0.0  0.0       0.0        0.0  0.0       0.0   0.0      0.0   \n",
       "2     0.0   0.0  0.0  0.0       0.0        0.0  0.0       0.0   0.0      0.0   \n",
       "3     0.0   0.0  0.0  0.0       0.0        0.0  0.0       0.0   0.0      0.0   \n",
       "4     0.0   0.0  0.0  0.0       0.0        0.0  0.0       0.0   0.0      0.0   \n",
       "...   ...   ...  ...  ...       ...        ...  ...       ...   ...      ...   \n",
       "5178  0.0   0.0  0.0  0.0       0.0        0.0  0.0       0.0   0.0      0.0   \n",
       "5179  0.0   0.0  0.0  0.0       0.0        0.0  0.0       0.0   0.0      0.0   \n",
       "5180  0.0   0.0  0.0  0.0       0.0        0.0  0.0       0.0   0.0      0.0   \n",
       "5181  0.0   0.0  0.0  0.0       0.0        0.0  0.0       0.0   0.0      0.0   \n",
       "5182  0.0   0.0  0.0  0.0       0.0        0.0  0.0       0.0   0.0      0.0   \n",
       "\n",
       "      ...  zygos  zygot  zymographi  zymosan  zymosaninduc  zyxin   zz  zzw  \\\n",
       "0     ...    0.0    0.0         0.0      0.0           0.0    0.0  0.0  0.0   \n",
       "1     ...    0.0    0.0         0.0      0.0           0.0    0.0  0.0  0.0   \n",
       "2     ...    0.0    0.0         0.0      0.0           0.0    0.0  0.0  0.0   \n",
       "3     ...    0.0    0.0         0.0      0.0           0.0    0.0  0.0  0.0   \n",
       "4     ...    0.0    0.0         0.0      0.0           0.0    0.0  0.0  0.0   \n",
       "...   ...    ...    ...         ...      ...           ...    ...  ...  ...   \n",
       "5178  ...    0.0    0.0         0.0      0.0           0.0    0.0  0.0  0.0   \n",
       "5179  ...    0.0    0.0         0.0      0.0           0.0    0.0  0.0  0.0   \n",
       "5180  ...    0.0    0.0         0.0      0.0           0.0    0.0  0.0  0.0   \n",
       "5181  ...    0.0    0.0         0.0      0.0           0.0    0.0  0.0  0.0   \n",
       "5182  ...    0.0    0.0         0.0      0.0           0.0    0.0  0.0  0.0   \n",
       "\n",
       "      zzz  zzzw  \n",
       "0     0.0   0.0  \n",
       "1     0.0   0.0  \n",
       "2     0.0   0.0  \n",
       "3     0.0   0.0  \n",
       "4     0.0   0.0  \n",
       "...   ...   ...  \n",
       "5178  0.0   0.0  \n",
       "5179  0.0   0.0  \n",
       "5180  0.0   0.0  \n",
       "5181  0.0   0.0  \n",
       "5182  0.0   0.0  \n",
       "\n",
       "[5183 rows x 30868 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining all the variables we need:\n",
    "k_1 = 1.2\n",
    "b = 0.8\n",
    "dfs = (dataframe > 0).sum(axis=0) # doc frequency\n",
    "N = dataframe.shape[0] # total number of docs\n",
    "idfs = np.log10(N/dfs) # inverse doc frequency\n",
    "#dls = [len(d.split(' ')) for d in documents] # considering all words in doc\n",
    "dls = dataframe.sum(axis=1).tolist() # considering words minus stop words in doc (better option)\n",
    "avgdl = np.mean(dls) # single value, mean doc length (minus stop words)\n",
    "\n",
    "# Applying the BM25 formula:\n",
    "numerator = np.array((k_1 + 1) * dataframe)\n",
    "denominator = np.array(k_1 *((1 - b) + b * (dls / avgdl))).reshape(N,1) + np.array(dataframe)\n",
    "BM25_tf = numerator / denominator\n",
    "idfs = np.array(idfs)\n",
    "BM25_score = BM25_tf * idfs\n",
    "\n",
    "bm25_idf = pd.DataFrame(BM25_score, columns=vocabulary)\n",
    "bm25_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1647985420059,
     "user": {
      "displayName": "Alexander C",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06292930002536064627"
     },
     "user_tz": 0
    },
    "id": "PotSpiIxltBy",
    "outputId": "6c94c3b6-57c2-4646-ca42-262b4735a35d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 in 5 million in UK have abnormal PrP positivity.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['abnormal', 'million', 'positivity', 'prp', 'uk'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_num = 1 #query number to test\n",
    "queries = []\n",
    "for q in dataset.queries_iter(): # reading in all the queries\n",
    "    queries.append([q[0],q[1]])\n",
    "print([queries[query_num][1]])\n",
    "\n",
    "vectorizer_q = CountVectorizer(stop_words='english', strip_accents='ascii')\n",
    "query_vectorized = vectorizer_q.fit_transform([queries[query_num][1]])\n",
    "q_terms = vectorizer_q.get_feature_names_out()\n",
    "q_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1647985425046,
     "user": {
      "displayName": "Alexander C",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06292930002536064627"
     },
     "user_tz": 0
    },
    "id": "ypvq9CGBl6Is",
    "outputId": "9dc14577-ddd4-4222-98b4-82d3b216523e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('OBJECTIVES To carry out a further survey of archived appendix samples to understand better the differences between existing estimates of the prevalence of subclinical infection with prions after the bovine spongiform encephalopathy epizootic and to see whether a broader birth cohort was affected, and to understand better the implications for the management of blood and blood products and for the handling of surgical instruments. DESIGN Irreversibly unlinked and anonymised large scale survey of archived appendix samples. SETTING Archived appendix samples from the pathology departments of 41 UK hospitals participating in the earlier survey, and additional hospitals in regions with lower levels of participation in that survey. SAMPLE 32,441 archived appendix samples fixed in formalin and embedded in paraffin and tested for the presence of abnormal prion protein (PrP). RESULTS Of the 32,441 appendix samples 16 were positive for abnormal PrP, indicating an overall prevalence of 493 per million population (95% confidence interval 282 to 801 per million). The prevalence in those born in 1941-60 (733 per million, 269 to 1596 per million) did not differ significantly from those born between 1961 and 1985 (412 per million, 198 to 758 per million) and was similar in both sexes and across the three broad geographical areas sampled. Genetic testing of the positive specimens for the genotype at PRNP codon 129 revealed a high proportion that were valine homozygous compared with the frequency in the normal population, and in stark contrast with confirmed clinical cases of vCJD, all of which were methionine homozygous at PRNP codon 129. CONCLUSIONS This study corroborates previous studies and suggests a high prevalence of infection with abnormal PrP, indicating vCJD carrier status in the population compared with the 177 vCJD cases to date. These findings have important implications for the management of blood and blood products and for the handling of surgical instruments.',\n",
       "  9.6599531137088),\n",
       " ('OBJECTIVE To assess the robustness of patient responses to a new national survey of patient experience as a basis for providing financial incentives to doctors. DESIGN Analysis of the representativeness of the respondents to the GP Patient Survey compared with those who were sampled (5.5 million patients registered with 8273 general practices in England in January 2009) and with the general population. Analysis of non-response bias looked at the relation between practice response rates and scores on the survey. Analysis of the reliability of the survey estimated the proportion of the variance of practice scores attributable to true differences between practices. RESULTS The overall response rate was 38.2% (2.2 million responses), which is comparable to that in surveys using similar methodology in the UK. Men, young adults, and people living in deprived areas were under-represented among respondents. However, for questions related to pay for performance, there was no systematic association between response rates and questionnaire scores. Two questions which triggered payments to general practitioners were reliable measures of practice performance, with average practice-level reliability coefficients of 93.2% and 95.0%. Less than 3% and 0.5% of practices had fewer than the number of responses required to achieve conventional reliability levels of 90% and 70%. A change to the payment formula in 2009 resulted in an increase in the average impact of random variation in patient scores on payments to general practitioners compared with payments made in 2007 and 2008. CONCLUSIONS There is little evidence to support the concern of some general practitioners that low response rates and selective non-response bias have led to systematic unfairness in payments attached to questionnaire scores. The study raises issues relating to the validity and reliability of payments based on patient surveys and provides lessons for the UK and for other countries considering the use of patient experience as part of pay for performance schemes.',\n",
       "  4.734095078261305),\n",
       " ('Antisense transcription is widespread in many genomes; however, how much is functional is hotly debated. We are investigating functionality of a set of long noncoding antisense transcripts, collectively called COOLAIR, produced at Arabidopsis FLOWERING LOCUS C (FLC). COOLAIR initiates just downstream of the major sense transcript poly(A) site and terminates either early or extends into the FLC promoter region. We now show that splicing of COOLAIR is functionally important. This was revealed through analysis of a hypomorphic mutation in the core spliceosome component PRP8. The prp8 mutation perturbs a cotranscriptional feedback mechanism linking COOLAIR processing to FLC gene body histone demethylation and reduced FLC transcription. The importance of COOLAIR splicing in this repression mechanism was confirmed by disrupting COOLAIR production and mutating the COOLAIR proximal splice acceptor site. Our findings suggest that altered splicing of a long noncoding transcript can quantitatively modulate gene expression through cotranscriptional coupling mechanisms.',\n",
       "  4.734030869021139),\n",
       " ('Ku70, a known nonhomologous end-joining (NHEJ) factor, also functions in tumor suppression, although this molecular mechanism remains uncharacterized. Previously, we showed that mice deficient for DNA ligase IV (Lig4), another key NHEJ factor, succumbed to aggressive lymphoma in the absence of tumor suppressor p53. However, the tumor phenotype is abrogated by the introduction of a hypomorphic mutant p53R172P, which impaired p53-mediated apoptosis but not cell-cycle arrest. However, Lig4−/−p53R172P mice succumbed to severe diabetes. To further elucidate the role of NHEJ and p53-mediated apoptosis in vivo, we bred Ku70−/− p53R172P mice. Unexpectedly, these mice were free of diabetes, although 80% of the mutant mice had abnormally enlarged colons with pronounced inflammation. Remarkably, most of these mutant mice progressed to dysplasia, adenoma and adenocarcinoma; this is in contrast to the Lig4−/−p53R172P phenotype, strongly suggesting an NHEJ-independent function of Ku70. Significantly, our analyses of Ku70−/−p53R172P colonic epithelial cells show nuclear stabilization of β-catenin accompanied by higher expression of cyclin D1 and c-Myc in affected colon sections than in control samples. This is not due to the p53 mutation, as Ku70−/− mice share this phenotype. Our results not only unravel a novel function of Ku70 essential for colon homeostasis, but also establish an excellent in vivo model in which to study how chronic inflammation and abnormal cellular proliferation underlie tumorigenesis and tumor progression in the colon.',\n",
       "  4.323900694571535),\n",
       " ('BACKGROUND The Global Burden of Diseases, Injuries, and Risk Factors Study 2015 provides an up-to-date synthesis of the evidence for risk factor exposure and the attributable burden of disease. By providing national and subnational assessments spanning the past 25 years, this study can inform debates on the importance of addressing risks in context. METHODS We used the comparative risk assessment framework developed for previous iterations of the Global Burden of Disease Study to estimate attributable deaths, disability-adjusted life-years (DALYs), and trends in exposure by age group, sex, year, and geography for 79 behavioural, environmental and occupational, and metabolic risks or clusters of risks from 1990 to 2015. This study included 388 risk-outcome pairs that met World Cancer Research Fund-defined criteria for convincing or probable evidence. We extracted relative risk and exposure estimates from randomised controlled trials, cohorts, pooled cohorts, household surveys, census data, satellite data, and other sources. We used statistical models to pool data, adjust for bias, and incorporate covariates. We developed a metric that allows comparisons of exposure across risk factors-the summary exposure value. Using the counterfactual scenario of theoretical minimum risk level, we estimated the portion of deaths and DALYs that could be attributed to a given risk. We decomposed trends in attributable burden into contributions from population growth, population age structure, risk exposure, and risk-deleted cause-specific DALY rates. We characterised risk exposure in relation to a Socio-demographic Index (SDI). FINDINGS Between 1990 and 2015, global exposure to unsafe sanitation, household air pollution, childhood underweight, childhood stunting, and smoking each decreased by more than 25%. Global exposure for several occupational risks, high body-mass index (BMI), and drug use increased by more than 25% over the same period. All risks jointly evaluated in 2015 accounted for 57·8% (95% CI 56·6-58·8) of global deaths and 41·2% (39·8-42·8) of DALYs. In 2015, the ten largest contributors to global DALYs among Level 3 risks were high systolic blood pressure (211·8 million [192·7 million to 231·1 million] global DALYs), smoking (148·6 million [134·2 million to 163·1 million]), high fasting plasma glucose (143·1 million [125·1 million to 163·5 million]), high BMI (120·1 million [83·8 million to 158·4 million]), childhood undernutrition (113·3 million [103·9 million to 123·4 million]), ambient particulate matter (103·1 million [90·8 million to 115·1 million]), high total cholesterol (88·7 million [74·6 million to 105·7 million]), household air pollution (85·6 million [66·7 million to 106·1 million]), alcohol use (85·0 million [77·2 million to 93·0 million]), and diets high in sodium (83·0 million [49·3 million to 127·5 million]). From 1990 to 2015, attributable DALYs declined for micronutrient deficiencies, childhood undernutrition, unsafe sanitation and water, and household air pollution; reductions in risk-deleted DALY rates rather than reductions in exposure drove these declines. Rising exposure contributed to notable increases in attributable DALYs from high BMI, high fasting plasma glucose, occupational carcinogens, and drug use. Environmental risks and childhood undernutrition declined steadily with SDI; low physical activity, high BMI, and high fasting plasma glucose increased with SDI. In 119 countries, metabolic risks, such as high BMI and fasting plasma glucose, contributed the most attributable DALYs in 2015. Regionally, smoking still ranked among the leading five risk factors for attributable DALYs in 109 countries; childhood underweight and unsafe sex remained primary drivers of early death and disability in much of sub-Saharan Africa. INTERPRETATION Declines in some key environmental risks have contributed to declines in critical infectious diseases. Some risks appear to be invariant to SDI. Increasing risks, including high BMI, high fasting plasma glucose, drug use, and some occupational exposures, contribute to rising burden from some conditions, but also provide opportunities for intervention. Some highly preventable risks, such as smoking, remain major causes of attributable DALYs, even as exposure is declining. Public policy makers need to pay attention to the risks that are increasingly major contributors to global burden. FUNDING Bill & Melinda Gates Foundation.',\n",
       "  3.5365319244526128),\n",
       " ('BACKGROUND Dengue is the most common arbovirus infection globally, but its burden is poorly quantified. We estimated dengue mortality, incidence, and burden for the Global Burden of Disease Study 2013. METHODS We modelled mortality from vital registration, verbal autopsy, and surveillance data using the Cause of Death Ensemble Modelling tool. We modelled incidence from officially reported cases, and adjusted our raw estimates for under-reporting based on published estimates of expansion factors. In total, we had 1780 country-years of mortality data from 130 countries, 1636 country-years of dengue case reports from 76 countries, and expansion factor estimates for 14 countries. FINDINGS We estimated an average of 9221 dengue deaths per year between 1990 and 2013, increasing from a low of 8277 (95% uncertainty estimate 5353-10 649) in 1992, to a peak of 11 302 (6790-13 722) in 2010. This yielded a total of 576 900 (330 000-701 200) years of life lost to premature mortality attributable to dengue in 2013. The incidence of dengue increased greatly between 1990 and 2013, with the number of cases more than doubling every decade, from 8·3 million (3·3 million-17·2 million) apparent cases in 1990, to 58·4 million (23·6 million-121·9 million) apparent cases in 2013. When accounting for disability from moderate and severe acute dengue, and post-dengue chronic fatigue, 566 000 (186 000-1 415 000) years lived with disability were attributable to dengue in 2013. Considering fatal and non-fatal outcomes together, dengue was responsible for 1·14 million (0·73 million-1·98 million) disability-adjusted life-years in 2013. INTERPRETATION Although lower than other estimates, our results offer more evidence that the true symptomatic incidence of dengue probably falls within the commonly cited range of 50 million to 100 million cases per year. Our mortality estimates are lower than those presented elsewhere and should be considered in light of the totality of evidence suggesting that dengue mortality might, in fact, be substantially higher. FUNDING Bill & Melinda Gates Foundation.',\n",
       "  3.454910886706618),\n",
       " (\"The current reference curves of stature and weight for the UK were first published in 1966 and have been used ever since despite increasing concern that they may not adequately describe the growth of present day British children. Using current data from seven sources new reference curves have been estimated from birth to 20 years for children in 1990. The great majority of the data are nationally representative. The analysis used Cole's LMS method and has produced efficient estimates of the conventional centiles and gives a good fit to the data. These curves differ from the currently used curves at key ages for both stature and weight. In view of the concerns expressed about the current curves and the differences between them and the new curves, it is proposed that the curves presented here should be adopted as the new UK reference curves.\",\n",
       "  3.199744783191709),\n",
       " ('BACKGROUND Age-specific effects of mammographic screening, and the timing of such effects, are a matter of debate. The results of the UK Age trial, which compared the effect of invitation to annual mammographic screening from age 40 years with commencement of screening at age 50 years on breast cancer mortality, have been reported at 10 years of follow-up and showed no significant difference in mortality between the trial groups. Here, we report the results of the UK Age trial after 17 years of follow-up. METHODS Women aged 39-41 from 23 UK NHS Breast Screening Programme units years were randomly assigned by individual randomisation (1:2) to either an intervention group offered annual screening by mammography up to and including the calendar year of their 48th birthday or to a control group receiving usual medical care (invited for screening at age 50 years and every 3 years thereafter). Both groups were stratified by general practice. We compared breast cancer incidence and mortality by time since randomisation. Analyses included all women randomly assigned who could be traced with the National Health Service Central Register and who had not died or emigrated before entry. The primary outcome measures were mortality from breast cancer (defined as deaths with breast cancer coded as the underlying cause of death) and breast cancer incidence, including in-situ, invasive, and total incidence. Because there is an interest in the timing of the mortality effect, we analysed the results in different follow-up periods. This trial is registered, number ISRCTN24647151. FINDINGS Between Oct 14, 1990, and Sept 25, 1997, 160 921 participants were randomly assigned; 53 883 women in the intervention group and 106 953 assigned to usual medical care were included in this analysis. After a median follow-up of 17 years (IQR 16·8-18·8), the rate ratio (RR) for breast cancer mortality was 0·88 (95% CI 0·74-1·04) from tumours diagnosed during the intervention phase. A significant reduction in breast cancer mortality was noted in the intervention group compared with the control group in the first 10 years after diagnosis (RR 0·75, 0·58-0·97) but not thereafter (RR 1·02, 0·80-1·30) from tumours diagnosed during the intervention phase. The overall breast cancer incidence during 17 year follow-up was similar between the intervention group and the control group (RR 0·98, 0·93-1·04). INTERPRETATION Our results support an early reduction in mortality from breast cancer with annual mammography screening in women aged 40-49 years. Further data are needed to fully understand long-term effects. Cumulative incidence figures suggest at worst a small amount of overdiagnosis. FUNDING National Institute for Health Research Health Technology Assessment programme and the American Cancer Society. Past funding was received from the Medical Research Council, Cancer Research UK, the UK Department of Health, and the US National Cancer Institute.',\n",
       "  3.0921850503571653),\n",
       " (\"Soil erosion is a major environmental threat to the sustainability and productive capacity of agriculture. During the last 40 years, nearly one-third of the world's arable land has been lost by erosion and continues to be lost at a rate of more than 10 million hectares per year. With the addition of a quarter of a million people each day, the world population's food demand is increasing at a time when per capita food productivity is beginning to decline.\",\n",
       "  3.0710204948466964),\n",
       " ('By the year 2000 there will be six million pregnant women and five to ten million children infected with HIV-1. Intervention strategies have been planned and in some instances already started. A timely and cost-effective strategy needs to take into account that most HIV-1 infected individuals reside in developing countries. Further studies are needed on immunological and virological factors affecting HIV-1 transmission from mother to child, on differential disease progression in affected children, and on transient infection.',\n",
       "  3.061557780559323)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_terms = [term for term in q_terms if term in bm25_idf.columns]\n",
    "q_terms_only_df = bm25_idf[q_terms]\n",
    "score_q_d = q_terms_only_df.sum(axis=1)\n",
    "documents = [doc[1] for doc in corpus]\n",
    "sorted(zip(documents,score_q_d.values), key = lambda tup:tup[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1647985434100,
     "user": {
      "displayName": "Alexander C",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06292930002536064627"
     },
     "user_tz": 0
    },
    "id": "EH1lTrrXcKy0"
   },
   "outputs": [],
   "source": [
    "qrels = []\n",
    "for qrel in dataset.qrels_iter(): # reading in all the relevancy scores\n",
    "    qrels.append(qrel)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP45C5+pJ3qwvqE9Lr9O36x",
   "collapsed_sections": [
    "MhN0gWKiBGiQ"
   ],
   "name": "Search_engine_v0.0.ipynb",
   "provenance": [
    {
     "file_id": "1PgPZf47UxhUdOgrcPmZZM99Q58IcLg1k",
     "timestamp": 1647958891868
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
